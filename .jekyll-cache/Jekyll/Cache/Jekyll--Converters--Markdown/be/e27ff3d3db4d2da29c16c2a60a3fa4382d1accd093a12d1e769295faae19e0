I"G<p>Automatically categorise all of the content on your website and upload the results to Google Analytics using Google Cloud Platform. This process can be scheduled so all new content is classified automatically.</p>

<amp-img src="/assets/images/nlp-ga.jpg" width="1280" height="720" layout="responsive"></amp-img>

<p>Here‚Äôs how you can scrape content from websites using an <a href="https://github.com/yujiosaka/headless-chrome-crawler">open-source web crawler</a>, run the content through Google‚Äôs pre-trained content classification model and then uploads the results to Google Analytics using the Google Analytics <a href="https://developers.google.com/analytics/devguides/config/mgmt/v3">Management API</a>.</p>

<h2 id="why">Why?</h2>

<p>Classifying your content allows content creators to see patterns and insights based on categories aassigned by Google and enables segmentation of users by reading habits. Categorising your content automatically also improves speed and accuracy while reducing manual labor.</p>

<h2 id="what-is-googles-nlp-api">What is Google‚Äôs NLP API?</h2>

<p>Google‚Äôs <a href="https://cloud.google.com/natural-language">Natural Language API</a> is one of Google‚Äôs machine leaning and AI products. It allows us to derive insights from unstructured text using the same deep machine learning technology that powers both Google Searchand the language-understanding system behind Google Assistant.</p>

<h2 id="how-it-works">How it works</h2>

<amp-img src="/assets/images/sheets-prophet-data-flow.png" width="1403" height="693" layout="responsive"></amp-img>

<p>The web crawler scrapes the relevant text content on the pages of your website and runs the result through Google‚Äôs Natural Language API which has the ability to classify documents in more than 700 predefined categories.</p>

<h2 id="how-to-set-it-up">How to set it up</h2>

<h2 id="set-up">Set up</h2>

<p>First you‚Äôll need to set up a Google Cloud Platform project and enable billing.</p>

<p>1) Create three custom dimensions in GA for <code class="language-plaintext highlighter-rouge">Primary Category</code>, <code class="language-plaintext highlighter-rouge">Subcategory</code> and <code class="language-plaintext highlighter-rouge">Secondary Subcategory</code></p>

<p>2) Set up a Data Import in GA with the type ‚ÄúContent‚Äù. For the data set schema: ‚ÄúKey‚Äù should be set to <code class="language-plaintext highlighter-rouge">Page</code> and ‚ÄúImported Data‚Äù should be set to the three new custom dimensions</p>

<p>3) Clone this repo <code class="language-plaintext highlighter-rouge">git clone https://github.com/alsjohnstone/scraper-classification.git</code></p>

<p>4) Enable NLP API and Analytics API in your GCP project</p>

<p>5) Create service worker account and download the credentials.json file</p>

<p>6) Update the config.json file</p>

<p>7) Create a new GCP storage bucket and add your config.json and credentials.json files</p>

<p>8) Update the bucket referenced in the install.sh file with your bucket</p>

<p>9) Run the command below to spin up a new GCP Compute Instance that will automatically shutdown after the crawl is complete.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute instances create scraper \
    --machine-type=n1-standard-16 \
    --metadata-from-file=startup-script=./install.sh \
    --scopes=cloud-platform \
    --zone=europe-west2-c
</code></pre></div></div>

<p>Restarting the GCP Compute Instance will automatically scrape, classify and upload the results to GA. You can schedule crawls using Cloud Scheduler.</p>

:ET